{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{"papermill":{"duration":0.030513,"end_time":"2022-03-11T19:31:01.468396","exception":false,"start_time":"2022-03-11T19:31:01.437883","status":"completed"},"tags":[],"id":"ZZDoJbSa8rVd"}},{"cell_type":"code","source":"!pip install albumentations==0.4.6\nimport albumentations \nfrom albumentations.pytorch import ToTensorV2","metadata":{"id":"JS-SIlUq9vuX","outputId":"4069df26-5add-499d-d8c6-280cb40ee5e7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('started')\nimport os\nimport numpy as np\nimport pandas as pd\nimport albumentations as A\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torch.optim.lr_scheduler\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torchvision\nfrom torchvision import transforms\nfrom tqdm import tqdm\nfrom functools import partial\nimport warnings  \nwarnings.filterwarnings('ignore')","metadata":{"papermill":{"duration":3.610476,"end_time":"2022-03-11T19:31:32.909213","exception":false,"start_time":"2022-03-11T19:31:29.298737","status":"completed"},"tags":[],"id":"K9HntU-b8rVl","outputId":"96ae26af-8acf-418b-a18f-2822fd4b6384","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport albumentations as A\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom tqdm.notebook import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom albumentations import Rotate \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport torchvision\nfrom torchvision import transforms\nfrom tqdm import tqdm\nimport warnings  \nwarnings.filterwarnings('ignore')","metadata":{"id":"x0Gjf22s8rVn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer\n%cd Ranger-Deep-Learning-Optimizer\n!pip install -e\n%cd ..","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pytorch_ranger","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pytorch_ranger import Ranger  # this is from ranger.py\nfrom pytorch_ranger import RangerVA  # this is from ranger913A.py\nfrom pytorch_ranger import RangerQH  # this is from rangerqh.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 42\nnum_epoch = 40\nBATCH_SIZE = 128\nimage_size = 224\nnum_workers = 4","metadata":{"papermill":{"duration":0.043867,"end_time":"2022-03-11T19:31:32.992623","exception":false,"start_time":"2022-03-11T19:31:32.948756","status":"completed"},"tags":[],"id":"pS178N_L8rVn","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{"papermill":{"duration":0.036523,"end_time":"2022-03-11T19:31:33.150518","exception":false,"start_time":"2022-03-11T19:31:33.113995","status":"completed"},"tags":[],"id":"TXmuYhu18rVo"}},{"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()","metadata":{"id":"ppCjwxnuMe8p","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv_path = '../input/vision-verse/data/train.csv'\ntrain_df = pd.read_csv(train_csv_path)\nle.fit(train_df.label)\ntrain_df['label'] = le.transform(train_df.label)\ntrain_df.head()\n# train_df = train_df.sample(1000)","metadata":{"papermill":{"duration":0.085043,"end_time":"2022-03-11T19:31:33.272252","exception":false,"start_time":"2022-03-11T19:31:33.187209","status":"completed"},"tags":[],"id":"ViuA9q798rVp","outputId":"0e1238ff-c2b6-484e-b010-e03a45f8b953","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe()","metadata":{"papermill":{"duration":0.059329,"end_time":"2022-03-11T19:31:33.369219","exception":false,"start_time":"2022-03-11T19:31:33.30989","status":"completed"},"tags":[],"id":"LYsWBQwr8rVq","outputId":"a442e2a1-453c-4a42-8934-e04414d8396f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['label'].value_counts()","metadata":{"papermill":{"duration":0.047079,"end_time":"2022-03-11T19:31:33.454003","exception":false,"start_time":"2022-03-11T19:31:33.406924","status":"completed"},"tags":[],"id":"FUyzEabR8rVq","outputId":"69631049-5a95-474d-e8b5-50483d876a67","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's see the distribution of each species\nsns.countplot(train_df.label)\nplt.xticks(rotation=90)","metadata":{"papermill":{"duration":0.296988,"end_time":"2022-03-11T19:31:33.789731","exception":false,"start_time":"2022-03-11T19:31:33.492743","status":"completed"},"tags":[],"id":"O-vcYEgE8rVr","outputId":"ee42e267-eec8-4906-d563-c0d3c9bbc195","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train-Test Split","metadata":{"papermill":{"duration":0.040659,"end_time":"2022-03-11T19:31:33.869762","exception":false,"start_time":"2022-03-11T19:31:33.829103","status":"completed"},"tags":[],"id":"Sk6FHc4R8rVr"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"papermill":{"duration":0.045597,"end_time":"2022-03-11T19:31:33.954337","exception":false,"start_time":"2022-03-11T19:31:33.90874","status":"completed"},"tags":[],"id":"91EBuoqj8rVr","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(\n    train_df['path'], train_df['label'], test_size=0.1, random_state=42)\nprint(X_train.dtype)\nprint(y_train.dtype)\nprint(X_test.dtype)\nprint(y_test.dtype)","metadata":{"papermill":{"duration":0.050858,"end_time":"2022-03-11T19:31:34.044266","exception":false,"start_time":"2022-03-11T19:31:33.993408","status":"completed"},"tags":[],"id":"G_lwgGtu8rVs","outputId":"39888d8f-df97-4395-a722-4987c3999a1d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(X_train), len(X_test), len(y_train), len(y_test))","metadata":{"papermill":{"duration":0.046531,"end_time":"2022-03-11T19:31:34.1311","exception":false,"start_time":"2022-03-11T19:31:34.084569","status":"completed"},"tags":[],"id":"mWlXO_Ul8rVs","outputId":"219243b1-433f-484b-e61c-07a1373eecff","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training Dataset","metadata":{"papermill":{"duration":0.039162,"end_time":"2022-03-11T19:31:34.209481","exception":false,"start_time":"2022-03-11T19:31:34.170319","status":"completed"},"tags":[],"id":"SxzfyA_D8rVs"}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, root_dir, X_train, y_train, transform):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.X_train = X_train\n        self.y_train=y_train\n    \n    def __len__(self):\n        return len(self.X_train)\n    \n    def __getitem__(self, index):\n        label = self.y_train.iloc[index]\n\n        image_path = f\"{self.root_dir}/{self.X_train.iloc[index]}\"\n#         print(image_path)\n        if '.gif' in image_path:\n            cap= cv2.VideoCapture(image_path)\n            ret, image = cap.read()\n            cap.release()\n        else:\n            image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        image = self.transform(image)\n        return image, torch.tensor(label)","metadata":{"papermill":{"duration":0.047483,"end_time":"2022-03-11T19:31:34.296053","exception":false,"start_time":"2022-03-11T19:31:34.24857","status":"completed"},"tags":[],"id":"fa2UW4t88rVt","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transforms = transforms.Compose([transforms.ToPILImage(),\n                                       transforms.Resize((image_size,image_size)),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize([0.5,0.5,0.5],\n                                                            [0.5,0.5,0.5])])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_dir = '../input/vision-verse'\n\ndataset = CustomDataset(root_dir,\n                        X_train, y_train,\n                        train_transforms)\n\ntrain_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = num_workers)","metadata":{"papermill":{"duration":0.045313,"end_time":"2022-03-11T19:31:34.641331","exception":false,"start_time":"2022-03-11T19:31:34.596018","status":"completed"},"tags":[],"id":"WY0Liz1H8rVv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_dataset = CustomDataset(root_dir,\n                        X_test, y_test,\n                        train_transforms)\n\nvalid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = num_workers)","metadata":{"papermill":{"duration":0.045272,"end_time":"2022-03-11T19:31:34.725921","exception":false,"start_time":"2022-03-11T19:31:34.680649","status":"completed"},"tags":[],"id":"BOwwsJ1x8rVv","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model architecture","metadata":{"papermill":{"duration":0.040531,"end_time":"2022-03-11T19:31:34.813111","exception":false,"start_time":"2022-03-11T19:31:34.77258","status":"completed"},"tags":[],"id":"UJiZ755Z8rVv"}},{"cell_type":"code","source":"class Conv2dAuto(nn.Conv2d):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.padding =  (self.kernel_size[0] // 2, self.kernel_size[1] // 2) # dynamic add padding based on the kernel_size\n        \nconv3x3 = partial(Conv2dAuto, kernel_size=3, bias=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def activation_func(activation):\n    return  nn.ModuleDict([\n        ['relu', nn.ReLU(inplace=True)],\n        ['leaky_relu', nn.LeakyReLU(negative_slope=0.01, inplace=True)],\n        ['selu', nn.SELU(inplace=True)],\n        ['none', nn.Identity()]\n    ])[activation]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, activation='relu'):\n        super().__init__()\n        self.in_channels, self.out_channels, self.activation = in_channels, out_channels, activation\n        self.blocks = nn.Identity()\n        self.activate = activation_func(activation)\n        self.shortcut = nn.Identity()   \n    \n    def forward(self, x):\n        residual = x\n        if self.should_apply_shortcut: residual = self.shortcut(x)\n        x = self.blocks(x)\n        x += residual\n        x = self.activate(x)\n        return x\n    \n    @property\n    def should_apply_shortcut(self):\n        return self.in_channels != self.out_channels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResidualBlock(ResidualBlock):\n    def __init__(self, in_channels, out_channels, expansion=1, downsampling=1, conv=conv3x3, *args, **kwargs):\n        super().__init__(in_channels, out_channels, *args, **kwargs)\n        self.expansion, self.downsampling, self.conv = expansion, downsampling, conv\n        self.shortcut = nn.Sequential(\n            nn.Conv2d(self.in_channels, self.expanded_channels, kernel_size=1,\n                      stride=self.downsampling, bias=False),\n            nn.BatchNorm2d(self.expanded_channels)) if self.should_apply_shortcut else None\n        \n        \n    @property\n    def expanded_channels(self):\n        return self.out_channels * self.expansion\n    \n    @property\n    def should_apply_shortcut(self):\n        return self.in_channels != self.expanded_channels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def conv_bn(in_channels, out_channels, conv, *args, **kwargs):\n    return nn.Sequential(conv(in_channels, out_channels, *args, **kwargs), nn.BatchNorm2d(out_channels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BasicBlock(ResidualBlock):\n    expansion = 1\n    def __init__(self, in_channels, out_channels, *args, **kwargs):\n        super().__init__(in_channels, out_channels, *args, **kwargs)\n        self.blocks = nn.Sequential(\n            conv_bn(self.in_channels, self.out_channels, conv=self.conv, bias=False, stride=self.downsampling),\n            activation_func(self.activation),\n            conv_bn(self.out_channels, self.expanded_channels, conv=self.conv, bias=False),\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BottleNeckBlock(ResidualBlock):\n    expansion = 4\n    def __init__(self, in_channels, out_channels, *args, **kwargs):\n        super().__init__(in_channels, out_channels, expansion=4, *args, **kwargs)\n        self.blocks = nn.Sequential(\n           conv_bn(self.in_channels, self.out_channels, self.conv, kernel_size=1),\n             activation_func(self.activation),\n             conv_bn(self.out_channels, self.out_channels, self.conv, kernel_size=3, stride=self.downsampling),\n             activation_func(self.activation),\n             conv_bn(self.out_channels, self.expanded_channels, self.conv, kernel_size=1),\n        )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Layer(nn.Module):\n    def __init__(self, in_channels, out_channels, block=BasicBlock, n=1, *args, **kwargs):\n        super().__init__()\n        # 'We perform downsampling directly by convolutional layers that have a stride of 2.'\n        downsampling = 2 if in_channels != out_channels else 1\n        self.blocks = nn.Sequential(\n            block(in_channels , out_channels, *args, **kwargs, downsampling=downsampling),\n            *[block(out_channels * block.expansion, \n                    out_channels, downsampling=1, *args, **kwargs) for _ in range(n - 1)]\n        )\n\n    def forward(self, x):\n        x = self.blocks(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, in_channels=3, blocks_sizes=[64, 128, 256, 512], deepths=[2,2,2,2], \n                 activation='relu', block=BasicBlock, *args, **kwargs):\n        super().__init__()\n        self.blocks_sizes = blocks_sizes\n        \n        self.gate = nn.Sequential(\n            nn.Conv2d(in_channels, self.blocks_sizes[0], kernel_size=7, stride=2, padding=3, bias=False),\n            nn.BatchNorm2d(self.blocks_sizes[0]),\n            activation_func(activation),\n            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        )\n        \n        self.in_out_block_sizes = list(zip(blocks_sizes, blocks_sizes[1:]))\n        self.blocks = nn.ModuleList([ \n            Layer(blocks_sizes[0], blocks_sizes[0], n=deepths[0], activation=activation, \n                        block=block,*args, **kwargs),\n            *[Layer(in_channels * block.expansion, \n                          out_channels, n=n, activation=activation, \n                          block=block, *args, **kwargs) \n              for (in_channels, out_channels), n in zip(self.in_out_block_sizes, deepths[1:])]       \n        ])\n        \n        \n    def forward(self, x):\n        x = self.gate(x)\n        for block in self.blocks:\n            x = block(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, in_features, n_classes):\n        super().__init__()\n        self.avg = nn.AdaptiveAvgPool2d((1, 1))\n        self.decoder = nn.Linear(in_features, n_classes)\n\n    def forward(self, x):\n        x = self.avg(x)\n        x = x.view(x.size(0), -1)\n        x = self.decoder(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class custom_model(nn.Module):\n    \n    def __init__(self, in_channels, n_classes, *args, **kwargs):\n        super().__init__()\n        self.encoder = Encoder(in_channels, *args, **kwargs)\n        self.decoder = Decoder(self.encoder.blocks[-1].blocks[-1].expanded_channels, n_classes)\n        \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def my_model(in_channels, n_classes, block=BasicBlock, *args, **kwargs):\n    return custom_model(in_channels, n_classes, block=block, deepths=[2, 2, 2, 2], *args, **kwargs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchsummary\nfrom torchsummary import summary\n\nmodel = my_model(3, 4)\nsummary(model.cuda(), (3, 224, 224))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, targets = next(iter(train_loader))\nimages.shape, targets.shape","metadata":{"papermill":{"duration":0.836666,"end_time":"2022-03-11T19:31:52.332198","exception":false,"start_time":"2022-03-11T19:31:51.495532","status":"completed"},"tags":[],"id":"8VHA-uKw8rVx","outputId":"6125a582-3474-4b6f-bfb7-3d30f7729e8a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)","metadata":{"papermill":{"duration":0.047397,"end_time":"2022-03-11T19:31:52.420901","exception":false,"start_time":"2022-03-11T19:31:52.373504","status":"completed"},"tags":[],"id":"GewGqWOu8rVy","outputId":"214b4345-10cb-4f1e-f301-38ab3e53d5e7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc","metadata":{"papermill":{"duration":0.04723,"end_time":"2022-03-11T19:31:52.509038","exception":false,"start_time":"2022-03-11T19:31:52.461808","status":"completed"},"tags":[],"id":"N8-0JKic8rVy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=1, gamma=2, reduce=True):\n        super(FocalLoss, self).__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n        self.reduce = reduce\n\n    def forward(self, inputs, targets):\n        BCE_loss = nn.CrossEntropyLoss()(inputs, targets)\n\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n\n        if self.reduce:\n            return torch.mean(F_loss)\n        else:\n            return F_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_s = 0\n\nmodel.to(device)\nEPOCHS = num_epoch\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma=0.8)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0 = 10)\nfor epoch in range(EPOCHS):\n    print(f'Epoch: {epoch+1}/{EPOCHS}')\n    if epoch == 0:\n        for param in model.parameters():\n            param.requires_grad = True\n\n    correct = 0\n    total = 0\n    losses = []\n    \n    for batch_idx, data in enumerate(tqdm(train_loader)):\n        images, targets = data\n        images = images.to(device)\n        targets = targets.to(device)\n        output = model(images)\n        loss = criterion(output, targets)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        \n        _, pred = torch.max(output, 1)\n        correct += (pred == targets).sum().item()\n        total += pred.size(0)\n        losses.append(loss.item())        \n        loss.detach()\n        del images, targets, output, loss\n        gc.collect()\n        \n    train_loss = np.mean(losses)\n    train_acc = correct * 1.0 / total\n    del losses\n    total=0\n    correct=0\n    with torch.no_grad():\n        for batch_idx, data in enumerate(tqdm(valid_loader)):\n            images, targets = data\n            images = images.to(device)\n            targets = targets.to(device)\n            \n            output = model(images)\n\n            _, pred = torch.max(output, 1)\n            correct += (pred == targets).sum().item()\n            \n            total += pred.size(0)\n\n        valid_acc = correct * 1.0 / total\n        # Saving State Dict\n    if valid_acc > best_s:\n        torch.save({\n            'model_state_dict': model.state_dict(),\n            'accuracy': correct\n        }, f'last_checkpoint.pth.tar')\n        best_s = valid_acc\n        print('best saved epoch ' + str(epoch))\n    print(f'Train Loss: {train_loss}\\tTrain Acc: {train_acc*100}\\tLR: {scheduler.get_lr()}\\tValid Accuracy: {correct/total * 100}')\n    scheduler.step()","metadata":{"papermill":{"duration":0.164507,"end_time":"2022-03-11T19:31:52.7151","exception":false,"start_time":"2022-03-11T19:31:52.550593","status":"completed"},"tags":[],"id":"bdbm98pK8rVy","outputId":"640a419d-cfac-47b7-d506-d437d2cae3ee","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache\ngc.collect()","metadata":{"id":"l2BFlMfH8rVy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make predictions","metadata":{"papermill":{"duration":0.041426,"end_time":"2022-03-11T19:31:52.797743","exception":false,"start_time":"2022-03-11T19:31:52.756317","status":"completed"},"tags":[],"id":"g_rQz_ff8rVz"}},{"cell_type":"code","source":"pre_path= './last_checkpoint.pth.tar' \nmodel.load_state_dict(torch.load(pre_path)['model_state_dict'])\nmodel.eval()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_csv_path = '../input/vision-verse/data/sample_submission.csv'\nsample_df = pd.read_csv(sample_csv_path)\n# sample_df['Class'] = le.transform(sample_df.Class)\nsample_df['label'] = 0\nsample_df.head()\n# sample_df[\"label\"] = pd.to_numeric(sample_df[\"label\"])","metadata":{"id":"v6s5gHjl8rVz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_final = sample_df['path']\ny_final = pd.to_numeric(sample_df[\"label\"])\nprint(X_final.dtype)\nprint(y_final.dtype)","metadata":{"id":"baUQs7598rVz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = CustomDataset('../input/vision-verse',\n                        X_final, y_final,\n                        test_transforms)\n\n\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers = num_workers)","metadata":{"id":"Q54uo6TD8rVz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = np.array([])\nwith torch.no_grad():\n    for batch_idx, data in enumerate(tqdm(test_loader)):\n        images, targets = data\n        images = images.to(device)\n        targets = targets.to(device)\n        \n        output = model(images)\n        _, pred = torch.max(output, 1)\n        label = np.concatenate((label, np.array(pred.cpu().data)), axis = 0)\n#         print(label)","metadata":{"id":"3FFlOL4H8rVz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df.head()","metadata":{"id":"atSGpv6a8rVz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df['label'] = label\nsample_df['label'] = sample_df[\"label\"].astype(int)\nsample_df['label'] = le.inverse_transform(sample_df['label'])","metadata":{"id":"ZKTaekCb8rV0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df.to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":5.766816,"end_time":"2022-03-11T20:18:16.320561","exception":false,"start_time":"2022-03-11T20:18:10.553745","status":"completed"},"tags":[],"id":"6uDo1v9-8rV0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df.shape","metadata":{"papermill":{"duration":5.637227,"end_time":"2022-03-11T20:18:27.904323","exception":false,"start_time":"2022-03-11T20:18:22.267096","status":"completed"},"tags":[],"id":"e0UswlnQ8rV0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df.head()","metadata":{"id":"A41yDvNd8rV0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df['label'].value_counts()","metadata":{"id":"HLeuX5lh8rV0","trusted":true},"execution_count":null,"outputs":[]}]}